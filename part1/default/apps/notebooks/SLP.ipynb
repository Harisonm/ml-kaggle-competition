{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model for CIFAR-10\n",
    "import numpy\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import cifar10\n",
    "from keras.losses import mse, logcosh, binary_crossentropy, categorical_crossentropy\n",
    "from keras.activations import relu, elu, softmax, sigmoid, linear\n",
    "from keras.constraints import maxnorm\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM, Reshape\n",
    "from keras.layers import TimeDistributed, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard\n",
    "import random\n",
    "import talos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Parametrage des hyper-paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = numpy.random.random() * (0.1 - 0.0001) + 0.0001\n",
    "momentum = numpy.random.random() * (0.1 - 0.0001) + 0.0001\n",
    "epochs = 1\n",
    "decay = lr / epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/envs/envPython37/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "Param = {'input_shape': 3072,\n",
    "             'input_shape_rnn': (32, 96),\n",
    "             'input_shape_cnn': (32, 32, 3),\n",
    "             'lr': lr,\n",
    "             'hidden_dim': 128,\n",
    "             'units': 512,\n",
    "             'unitsSlp': 10,\n",
    "             'last_units': 10,\n",
    "             'first_neuron': [4, 8, 16, 32, 64],\n",
    "             'hidden_layers': [2, 4, 6, 8, 9, 10, 20, 25, 30],\n",
    "             'kernel_constraint': maxnorm(3),\n",
    "             'batch_size': (64, 128, 512, 1024, 2048),\n",
    "             'epochs': epochs,\n",
    "             'dropout': (0, 0.5, 1),\n",
    "             'padding': 'same',\n",
    "             'metrics': ['accuracy'],\n",
    "             'weight_regulizer': [None],\n",
    "             'emb_output_dims': [None],\n",
    "             'shape': ['brick', 'long_funnel'],\n",
    "             'optimizer': ['adam', 'Nadam', 'RMSprop', SGD(lr=lr, momentum=momentum, decay=decay, nesterov=False)],\n",
    "             'losses': [mse, logcosh, binary_crossentropy, categorical_crossentropy],\n",
    "             'activation': [relu, elu, linear],\n",
    "             'last_activation': [softmax, sigmoid],\n",
    "             'nb_classes': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _random_param(param):\n",
    "    \"\"\"\n",
    "    _random_param : do random to param values\n",
    "    :param param:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    rand_param = {'input_shape': param['input_shape'],\n",
    "                  'input_shape_cnn': param['input_shape_cnn'],\n",
    "                  'input_shape_rnn': param['input_shape_rnn'],\n",
    "                  'lr': param['lr'],\n",
    "                  'hidden_dim': param['hidden_dim'],\n",
    "                  'units': param['units'],\n",
    "                  'unitsSlp': param['unitsSlp'],\n",
    "                  'padding': param['padding'],\n",
    "                  'last_units': param['last_units'],\n",
    "                  'first_neuron': random.choice(param['first_neuron']),\n",
    "                  'hidden_layers': random.choice(param['hidden_layers']),\n",
    "                  'kernel_constraint': param['kernel_constraint'],\n",
    "                  'batch_size': random.choice(param['batch_size']),\n",
    "                  'epochs': param['epochs'],\n",
    "                  'dropout': random.choice(param['dropout']),\n",
    "                  'metrics': param['metrics'],\n",
    "                  'weight_regulizer': param['weight_regulizer'],\n",
    "                  'emb_output_dims': ['emb_output_dims'],\n",
    "                  'shape': random.choice(param['shape']),\n",
    "                  'optimizer': random.choice(param['optimizer']),\n",
    "                  'losses': random.choice(param['losses']),\n",
    "                  'activation': random.choice(param['activation']),\n",
    "                  'last_activation': random.choice(param['last_activation']),\n",
    "                  'nb_classes': param['nb_classes']}\n",
    "    return rand_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Prétraitement de la donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_cifar10(param):\n",
    "    \"\"\"\n",
    "    :param dataset:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    (__X_train, __y_train), (__X_test, __y_test) = cifar10.load_data()\n",
    "    __X_train = __X_train.reshape(50000, 32 * 32 * 3)\n",
    "    __X_test = __X_test.reshape(10000, 32 * 32 * 3)\n",
    "\n",
    "    __X_train = __X_train.astype('float32')\n",
    "    __X_test = __X_test.astype('float32')\n",
    "    __X_train /= 255.0\n",
    "    __X_test /= 255.0\n",
    "\n",
    "    __y_train = np_utils.to_categorical(__y_train, param['nb_classes'])\n",
    "    __y_test = np_utils.to_categorical(__y_test, param['nb_classes'])\n",
    "    return (__X_train, __y_train), (__X_test, __y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Charge et prépare le dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 183s 1us/step\n"
     ]
    }
   ],
   "source": [
    "param = _random_param(Param)\n",
    "dataset = _preprocess_cifar10(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = dataset\n",
    "nb_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Gestion du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Declaration du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ajout des couches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(param['unitsSlp'],\n",
    "                input_shape=(param['input_shape'],),\n",
    "                activation=param['activation']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. compile le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                30730     \n",
      "=================================================================\n",
      "Total params: 30,730\n",
      "Trainable params: 30,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=param['losses'],\n",
    "              optimizer=param['optimizer'],\n",
    "              metrics=param['metrics'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entrainement le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/envs/envPython37/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 10.6624 - acc: 0.1440 - val_loss: 10.5494 - val_acc: 0.1553\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=param['batch_size'],\n",
    "                    epochs=param['epochs'],\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evalue le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 30us/step\n",
      "test loss: 10.549419343566894\n",
      "test acc: 0.1553\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "print('test loss:', score[0])\n",
    "print('test acc:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.549419343566894, 0.1553]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (envPython37)",
   "language": "python",
   "name": "envpython37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
