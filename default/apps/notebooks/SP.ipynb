{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Simple CNN model for CIFAR-10\n",
    "import numpy\n",
    "import talos\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard\n",
    "K.set_image_dim_ordering('th')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctionnement d'un perceptron simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_history(history, result_file):\n",
    "    loss = history.history['loss']\n",
    "    acc = history.history['acc']\n",
    "    val_loss = history.history['val_loss']\n",
    "    val_acc = history.history['val_acc']\n",
    "    nb_epoch = len(acc)\n",
    "\n",
    "    with open(result_file, \"w\") as fp:\n",
    "        fp.write(\"epoch\\tloss\\tacc\\tval_loss\\tval_acc\\n\")\n",
    "        for i in range(nb_epoch):\n",
    "            fp.write(\"%d\\t%f\\t%f\\t%f\\t%f\\n\" %\n",
    "                     (i, loss[i], acc[i], val_loss[i], val_acc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 200\n",
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
    "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, input_shape=(3072, ), activation='relu', kernel_constraint=maxnorm(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              3146752   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,157,002\n",
      "Trainable params: 3,157,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 24s 488us/step - loss: 7.9897 - acc: 0.1597 - val_loss: 7.4193 - val_acc: 0.2108\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 26s 530us/step - loss: 7.4745 - acc: 0.1465 - val_loss: 7.4845 - val_acc: 0.1558\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 25s 492us/step - loss: 7.4508 - acc: 0.1798 - val_loss: 7.4136 - val_acc: 0.1910\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 26s 515us/step - loss: 7.4412 - acc: 0.1894 - val_loss: 7.4381 - val_acc: 0.1349\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 25s 509us/step - loss: 7.4328 - acc: 0.1992 - val_loss: 7.4012 - val_acc: 0.2279\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 26s 515us/step - loss: 7.4463 - acc: 0.1796 - val_loss: 7.4371 - val_acc: 0.1912 loss: 7.4471 - acc: 0.179 - ETA: 0s - loss: 7.447\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 25s 497us/step - loss: 7.4124 - acc: 0.2325 - val_loss: 7.4323 - val_acc: 0.2377\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 24s 475us/step - loss: 7.3939 - acc: 0.2264 - val_loss: 7.3823 - val_acc: 0.2445\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 25s 503us/step - loss: 7.3838 - acc: 0.2240 - val_loss: 7.3883 - val_acc: 0.2494\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 25s 502us/step - loss: 7.3895 - acc: 0.2350 - val_loss: 7.3594 - val_acc: 0.2415\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 24s 488us/step - loss: 7.4229 - acc: 0.1763 - val_loss: 7.3979 - val_acc: 0.2463\n",
      "Epoch 12/200\n",
      " 3584/50000 [=>............................] - ETA: 26s - loss: 7.7209 - acc: 0.1261"
     ]
    }
   ],
   "source": [
    "# training\n",
    "    history = model.fit(X_train, Y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        nb_epoch=nb_epoch,\n",
    "                        verbose=1,\n",
    "                        validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_history(history, 'history.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(X_test, Y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test loss:', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test acc:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (envPython36)",
   "language": "python",
   "name": "envpython36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
