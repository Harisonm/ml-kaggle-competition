{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from keras.metrics import binary_accuracy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "import numpy as np\n",
    "from keras.optimizers import sgd, rmsprop, adam\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import make_regression\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split \n",
    "from matplotlib import pyplot\n",
    "# fix random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctionnement du MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='pictures/PerceptronSimple.png', width=500, height=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plusieurs perceptron Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='pictures/MLP.png', width=500, height=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Déclaration et préparation des données d'entrainement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## charge et prépare le dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prépare dataset\n",
    "# Charge et prépare le dataset\n",
    "dataset = numpy.genfromtxt(\"../dataset/Concrete_Data_Yeh.csv\", delimiter=\",\",skip_header=1)\n",
    "readData = pd.read_csv(\"../dataset/Concrete_Data_Yeh.csv\", delimiter=\",\")\n",
    "readData.head()\n",
    "readData.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input\n",
    "X = dataset[:,0:8]\n",
    "\n",
    "#Normalization of data\n",
    "# Create a minimum and maximum processor object\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "# Create an object to transform the data to fit minmax processor\n",
    "x_scaled = min_max_scaler.fit_transform(X)\n",
    "\n",
    "# Run the normalizer on the dataframe\n",
    "X = pd.DataFrame(x_scaled)\n",
    "\n",
    "# View the dataframe\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OutPut predict\n",
    "Y = dataset[:,8]\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Découpage pour équibrer le training et test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "#decoupage facon equilibré par rapport a y \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.3,random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X))#taille de X\n",
    "print(len(X_test))#taille test 30%\n",
    "print(len(X_train))#taille d'entrainment 70%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Defini le réseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The first layer,8 input variables\n",
    "#initialize the network weights to a small random number generated from :\n",
    "# uniform : in this case between 0 and 0.05 because that is the default uniform weight initialization in Keras\n",
    "# normal : for small random numbers generated from a Gaussian distribution.\n",
    "\n",
    "model.add(Dense(4, input_dim=8, kernel_initializer='normal', activation='tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#second hidden layer has 8 neurons\n",
    "model.add(Dense(8, kernel_initializer='normal', activation='tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 hidden layer has 8 neurons\n",
    "#model.add(Dense(8, kernel_initializer='normal', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output layer has 1 neuron\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. compile le réseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='sgd',metrics=['accuracy'])\n",
    "\n",
    "#Régression : erreur quadratique moyenne ou « MSE ».\n",
    "#Stochastique Descente du Gradient ou « sgd » qui nécessite la mise au point d'un taux d'apprentissage et dynamique.\n",
    "#ADAM ou « adam » qui nécessite le réglage de la vitesse d'apprentissage.\n",
    "#RMSprop ou « rmsprop » qui nécessite le réglage de la vitesse d'apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. construit le réseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = \"7_Layer_MLP_1000_tanh_surapp2/\"\n",
    "tb_callback = keras.callbacks.TensorBoard('./logs/' + experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "# Construction du modele\n",
    "model.fit(X_train,Y_train, epochs=2000, verbose=0, callbacks = [tb_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. evalue le réseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the network\n",
    "loss, accuracy = model.evaluate(X_train, Y_train)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "probabilities = model.predict(X_test)\n",
    "diff = [len(Y_test)]\n",
    "# round predictions\n",
    "# show the inputs and predicted outputs\n",
    "for i in range(len(Y_test)):\n",
    "    print(\"Y=%s, Predicted=%s\" % (Y_test[i], probabilities[i]))\n",
    "    diff.append(abs((probabilities[i] - Y_test[i]) / Y_test[i] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparaison Train et Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moyen = sum(diff) / float(len(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moyen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (envPython36)",
   "language": "python",
   "name": "envpython36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
